{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets,preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.. _breast_cancer_dataset:',\n",
       " '',\n",
       " 'Breast cancer wisconsin (diagnostic) dataset',\n",
       " '--------------------------------------------',\n",
       " '',\n",
       " '**Data Set Characteristics:**',\n",
       " '',\n",
       " '    :Number of Instances: 569',\n",
       " '',\n",
       " '    :Number of Attributes: 30 numeric, predictive attributes and the class',\n",
       " '',\n",
       " '    :Attribute Information:',\n",
       " '        - radius (mean of distances from center to points on the perimeter)',\n",
       " '        - texture (standard deviation of gray-scale values)',\n",
       " '        - perimeter',\n",
       " '        - area',\n",
       " '        - smoothness (local variation in radius lengths)',\n",
       " '        - compactness (perimeter^2 / area - 1.0)',\n",
       " '        - concavity (severity of concave portions of the contour)',\n",
       " '        - concave points (number of concave portions of the contour)',\n",
       " '        - symmetry ',\n",
       " '        - fractal dimension (\"coastline approximation\" - 1)',\n",
       " '',\n",
       " '        The mean, standard error, and \"worst\" or largest (mean of the three',\n",
       " '        largest values) of these features were computed for each image,',\n",
       " '        resulting in 30 features.  For instance, field 3 is Mean Radius, field',\n",
       " '        13 is Radius SE, field 23 is Worst Radius.',\n",
       " '',\n",
       " '        - class:',\n",
       " '                - WDBC-Malignant',\n",
       " '                - WDBC-Benign',\n",
       " '',\n",
       " '    :Summary Statistics:',\n",
       " '',\n",
       " '    ===================================== ====== ======',\n",
       " '                                           Min    Max',\n",
       " '    ===================================== ====== ======',\n",
       " '    radius (mean):                        6.981  28.11',\n",
       " '    texture (mean):                       9.71   39.28',\n",
       " '    perimeter (mean):                     43.79  188.5',\n",
       " '    area (mean):                          143.5  2501.0',\n",
       " '    smoothness (mean):                    0.053  0.163',\n",
       " '    compactness (mean):                   0.019  0.345',\n",
       " '    concavity (mean):                     0.0    0.427',\n",
       " '    concave points (mean):                0.0    0.201',\n",
       " '    symmetry (mean):                      0.106  0.304',\n",
       " '    fractal dimension (mean):             0.05   0.097',\n",
       " '    radius (standard error):              0.112  2.873',\n",
       " '    texture (standard error):             0.36   4.885',\n",
       " '    perimeter (standard error):           0.757  21.98',\n",
       " '    area (standard error):                6.802  542.2',\n",
       " '    smoothness (standard error):          0.002  0.031',\n",
       " '    compactness (standard error):         0.002  0.135',\n",
       " '    concavity (standard error):           0.0    0.396',\n",
       " '    concave points (standard error):      0.0    0.053',\n",
       " '    symmetry (standard error):            0.008  0.079',\n",
       " '    fractal dimension (standard error):   0.001  0.03',\n",
       " '    radius (worst):                       7.93   36.04',\n",
       " '    texture (worst):                      12.02  49.54',\n",
       " '    perimeter (worst):                    50.41  251.2',\n",
       " '    area (worst):                         185.2  4254.0',\n",
       " '    smoothness (worst):                   0.071  0.223',\n",
       " '    compactness (worst):                  0.027  1.058',\n",
       " '    concavity (worst):                    0.0    1.252',\n",
       " '    concave points (worst):               0.0    0.291',\n",
       " '    symmetry (worst):                     0.156  0.664',\n",
       " '    fractal dimension (worst):            0.055  0.208',\n",
       " '    ===================================== ====== ======',\n",
       " '',\n",
       " '    :Missing Attribute Values: None',\n",
       " '',\n",
       " '    :Class Distribution: 212 - Malignant, 357 - Benign',\n",
       " '',\n",
       " '    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian',\n",
       " '',\n",
       " '    :Donor: Nick Street',\n",
       " '',\n",
       " '    :Date: November, 1995',\n",
       " '',\n",
       " 'This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.',\n",
       " 'https://goo.gl/U2Uwz2',\n",
       " '',\n",
       " 'Features are computed from a digitized image of a fine needle',\n",
       " 'aspirate (FNA) of a breast mass.  They describe',\n",
       " 'characteristics of the cell nuclei present in the image.',\n",
       " '',\n",
       " 'Separating plane described above was obtained using',\n",
       " 'Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree',\n",
       " 'Construction Via Linear Programming.\" Proceedings of the 4th',\n",
       " 'Midwest Artificial Intelligence and Cognitive Science Society,',\n",
       " 'pp. 97-101, 1992], a classification method which uses linear',\n",
       " 'programming to construct a decision tree.  Relevant features',\n",
       " 'were selected using an exhaustive search in the space of 1-4',\n",
       " 'features and 1-3 separating planes.',\n",
       " '',\n",
       " 'The actual linear program used to obtain the separating plane',\n",
       " 'in the 3-dimensional space is that described in:',\n",
       " '[K. P. Bennett and O. L. Mangasarian: \"Robust Linear',\n",
       " 'Programming Discrimination of Two Linearly Inseparable Sets\",',\n",
       " 'Optimization Methods and Software 1, 1992, 23-34].',\n",
       " '',\n",
       " 'This database is also available through the UW CS ftp server:',\n",
       " '',\n",
       " 'ftp ftp.cs.wisc.edu',\n",
       " 'cd math-prog/cpo-dataset/machine-learn/WDBC/',\n",
       " '',\n",
       " '.. topic:: References',\n",
       " '',\n",
       " '   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction ',\n",
       " '     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on ',\n",
       " '     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,',\n",
       " '     San Jose, CA, 1993.',\n",
       " '   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and ',\n",
       " '     prognosis via linear programming. Operations Research, 43(4), pages 570-577, ',\n",
       " '     July-August 1995.',\n",
       " '   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques',\n",
       " '     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) ',\n",
       " '     163-171.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer.DESCR.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = breast_cancer.data\n",
    "Y = breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2            3           4   \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    14.127292   19.289649   91.969033   654.889104    0.096360   \n",
       "std      3.524049    4.301036   24.298981   351.914129    0.014064   \n",
       "min      6.981000    9.710000   43.790000   143.500000    0.052630   \n",
       "25%     11.700000   16.170000   75.170000   420.300000    0.086370   \n",
       "50%     13.370000   18.840000   86.240000   551.100000    0.095870   \n",
       "75%     15.780000   21.800000  104.100000   782.700000    0.105300   \n",
       "max     28.110000   39.280000  188.500000  2501.000000    0.163400   \n",
       "\n",
       "               5           6           7           8           9      ...      \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000     ...       \n",
       "mean     0.104341    0.088799    0.048919    0.181162    0.062798     ...       \n",
       "std      0.052813    0.079720    0.038803    0.027414    0.007060     ...       \n",
       "min      0.019380    0.000000    0.000000    0.106000    0.049960     ...       \n",
       "25%      0.064920    0.029560    0.020310    0.161900    0.057700     ...       \n",
       "50%      0.092630    0.061540    0.033500    0.179200    0.061540     ...       \n",
       "75%      0.130400    0.130700    0.074000    0.195700    0.066120     ...       \n",
       "max      0.345400    0.426800    0.201200    0.304000    0.097440     ...       \n",
       "\n",
       "               20          21          22           23          24  \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    16.269190   25.677223  107.261213   880.583128    0.132369   \n",
       "std      4.833242    6.146258   33.602542   569.356993    0.022832   \n",
       "min      7.930000   12.020000   50.410000   185.200000    0.071170   \n",
       "25%     13.010000   21.080000   84.110000   515.300000    0.116600   \n",
       "50%     14.970000   25.410000   97.660000   686.500000    0.131300   \n",
       "75%     18.790000   29.720000  125.400000  1084.000000    0.146000   \n",
       "max     36.040000   49.540000  251.200000  4254.000000    0.222600   \n",
       "\n",
       "               25          26          27          28          29  \n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  \n",
       "mean     0.254265    0.272188    0.114606    0.290076    0.083946  \n",
       "std      0.157336    0.208624    0.065732    0.061867    0.018061  \n",
       "min      0.027290    0.000000    0.000000    0.156500    0.055040  \n",
       "25%      0.147200    0.114500    0.064930    0.250400    0.071460  \n",
       "50%      0.211900    0.226700    0.099930    0.282200    0.080040  \n",
       "75%      0.339100    0.382900    0.161400    0.317900    0.092080  \n",
       "max      1.058000    1.252000    0.291000    0.663800    0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = pd.DataFrame(X)\n",
    "X_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,Y_train,Y_val = model_selection.train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting column of ones in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = np.append(X_train_scaled,np.ones(X_train_scaled.shape[0]).reshape(-1,1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 31), (31,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape,X_train_scaled[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(agg):\n",
    "    \n",
    "    return 1/(1+np.exp(-agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(X_train,Y_train,m):\n",
    "    \n",
    "    cost_ = 0\n",
    "    N = X_train.shape[0]\n",
    "    for i in range(N):\n",
    "        agg = (X_train[i]*m).sum()\n",
    "        h = sigmoid(agg)\n",
    "        cost = -Y_train[i]*np.log(h) - (1-Y_train[i])*np.log(1-h)\n",
    "        cost_ += cost\n",
    "    \n",
    "    return cost_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(X_train,Y_train,lr,m):\n",
    "    \n",
    "    N = X_train.shape[0]\n",
    "    slope_m = np.zeros(X_train.shape[1])\n",
    "    for i in range(N):\n",
    "        agg = (X_train[i]*m).sum()\n",
    "        h = sigmoid(agg)\n",
    "        slope_m+=(-1/N)*(Y_train[i]-h)*X_train[i]\n",
    "        \n",
    "    m = m - lr*slope_m\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train,Y_train,epochs=100,lr=0.01):\n",
    "    \n",
    "    m = np.zeros(X_train.shape[1])\n",
    "    cost_array = []\n",
    "    unit = epochs//100\n",
    "    for i in range(epochs):\n",
    "        m = step_gradient(X_train,Y_train,lr,m)\n",
    "        cost_ = cost(X_train,Y_train,m)\n",
    "        cost_array.append(cost_)\n",
    "        if i%unit==0:\n",
    "            print(\"Epoch:{}, Cost:{}\".format(i,cost_))\n",
    "    \n",
    "    return m,cost_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test,m):\n",
    "    \n",
    "    y_pred = []\n",
    "    N = X_test.shape[0]\n",
    "    for i in range(N):\n",
    "        agg = (X_test[i]*m).sum()\n",
    "        h = sigmoid(agg)\n",
    "        if h>=0.5:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "            \n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(Y_test,Y_pred):\n",
    "    \n",
    "    correct = 0\n",
    "    N = Y_test.shape[0]\n",
    "    correct = (Y_test==Y_pred).sum()\n",
    "    \n",
    "    return (correct/N)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Cost:287.0290218832631\n",
      "Epoch:50, Cost:143.62481625529517\n",
      "Epoch:100, Cost:110.43596891193037\n",
      "Epoch:150, Cost:94.4234213428991\n",
      "Epoch:200, Cost:84.61273121778811\n",
      "Epoch:250, Cost:77.83535241300412\n",
      "Epoch:300, Cost:72.8022235122822\n",
      "Epoch:350, Cost:68.87899702729509\n",
      "Epoch:400, Cost:65.71287356013663\n",
      "Epoch:450, Cost:63.09009927281048\n",
      "Epoch:500, Cost:60.872686184341504\n",
      "Epoch:550, Cost:58.967086442403065\n",
      "Epoch:600, Cost:57.30735638680932\n",
      "Epoch:650, Cost:55.845505799465094\n",
      "Epoch:700, Cost:54.54567081639308\n",
      "Epoch:750, Cost:53.380441463561006\n",
      "Epoch:800, Cost:52.32846221214753\n",
      "Epoch:850, Cost:51.37281530577109\n",
      "Epoch:900, Cost:50.49990213281007\n",
      "Epoch:950, Cost:49.69865100411659\n",
      "Epoch:1000, Cost:48.95994446843398\n",
      "Epoch:1050, Cost:48.27619771261228\n",
      "Epoch:1100, Cost:47.64104308478509\n",
      "Epoch:1150, Cost:47.04909053874022\n",
      "Epoch:1200, Cost:46.49574329938827\n",
      "Epoch:1250, Cost:45.97705430069288\n",
      "Epoch:1300, Cost:45.48961314248148\n",
      "Epoch:1350, Cost:45.0304561786953\n",
      "Epoch:1400, Cost:44.59699434028416\n",
      "Epoch:1450, Cost:44.18695469956649\n",
      "Epoch:1500, Cost:43.79833278642916\n",
      "Epoch:1550, Cost:43.42935339355326\n",
      "Epoch:1600, Cost:43.07843814055726\n",
      "Epoch:1650, Cost:42.744178461736716\n",
      "Epoch:1700, Cost:42.42531297770233\n",
      "Epoch:1750, Cost:42.12070843473319\n",
      "Epoch:1800, Cost:41.82934356618503\n",
      "Epoch:1850, Cost:41.550295361507764\n",
      "Epoch:1900, Cost:41.282727330186546\n",
      "Epoch:1950, Cost:41.02587942744416\n",
      "Epoch:2000, Cost:40.77905937111997\n",
      "Epoch:2050, Cost:40.54163512871627\n",
      "Epoch:2100, Cost:40.313028393127716\n",
      "Epoch:2150, Cost:40.09270889726389\n",
      "Epoch:2200, Cost:39.88018944334178\n",
      "Epoch:2250, Cost:39.675021543353736\n",
      "Epoch:2300, Cost:39.476791584110536\n",
      "Epoch:2350, Cost:39.28511744409732\n",
      "Epoch:2400, Cost:39.09964550076232\n",
      "Epoch:2450, Cost:38.92004797626777\n",
      "Epoch:2500, Cost:38.74602057753828\n",
      "Epoch:2550, Cost:38.577280392948445\n",
      "Epoch:2600, Cost:38.413564013431234\n",
      "Epoch:2650, Cost:38.254625850357336\n",
      "Epoch:2700, Cost:38.10023662638438\n",
      "Epoch:2750, Cost:37.950182018726146\n",
      "Epoch:2800, Cost:37.8042614370539\n",
      "Epoch:2850, Cost:37.6622869205849\n",
      "Epoch:2900, Cost:37.52408214092049\n",
      "Epoch:2950, Cost:37.389481498905624\n",
      "Epoch:3000, Cost:37.25832930525635\n",
      "Epoch:3050, Cost:37.130479035963674\n",
      "Epoch:3100, Cost:37.005792654577135\n",
      "Epoch:3150, Cost:36.88413999441284\n",
      "Epoch:3200, Cost:36.765398194551565\n",
      "Epoch:3250, Cost:36.64945118420207\n",
      "Epoch:3300, Cost:36.53618921062462\n",
      "Epoch:3350, Cost:36.425508406351184\n",
      "Epoch:3400, Cost:36.317310391910965\n",
      "Epoch:3450, Cost:36.21150191068293\n",
      "Epoch:3500, Cost:36.1079944928655\n",
      "Epoch:3550, Cost:36.00670414586719\n",
      "Epoch:3600, Cost:35.90755106871068\n",
      "Epoch:3650, Cost:35.81045938828797\n",
      "Epoch:3700, Cost:35.715356915526435\n",
      "Epoch:3750, Cost:35.622174919720536\n",
      "Epoch:3800, Cost:35.530847919458495\n",
      "Epoch:3850, Cost:35.441313488725484\n",
      "Epoch:3900, Cost:35.353512076904636\n",
      "Epoch:3950, Cost:35.26738684151746\n",
      "Epoch:4000, Cost:35.18288349265676\n",
      "Epoch:4050, Cost:35.09995014816082\n",
      "Epoch:4100, Cost:35.018537198667445\n",
      "Epoch:4150, Cost:34.938597181763974\n",
      "Epoch:4200, Cost:34.860084664519\n",
      "Epoch:4250, Cost:34.78295613374816\n",
      "Epoch:4300, Cost:34.707169893419874\n",
      "Epoch:4350, Cost:34.63268596866108\n",
      "Epoch:4400, Cost:34.5594660158684\n",
      "Epoch:4450, Cost:34.487473238473086\n",
      "Epoch:4500, Cost:34.416672307944765\n",
      "Epoch:4550, Cost:34.34702928965526\n",
      "Epoch:4600, Cost:34.278511573253596\n",
      "Epoch:4650, Cost:34.21108780723269\n",
      "Epoch:4700, Cost:34.14472783739345\n",
      "Epoch:4750, Cost:34.07940264893535\n",
      "Epoch:4800, Cost:34.01508431192507\n",
      "Epoch:4850, Cost:33.95174592991262\n",
      "Epoch:4900, Cost:33.88936159148345\n",
      "Epoch:4950, Cost:33.8279063245512\n",
      "[-0.50551861 -0.48649868 -0.4871194  -0.5265519  -0.22913863  0.01846826\n",
      " -0.52398903 -0.60158934 -0.02291878  0.30591297 -0.62066215 -0.03343191\n",
      " -0.40147666 -0.51622831 -0.0620317   0.38155071  0.0263002  -0.05572506\n",
      "  0.17296834  0.32139292 -0.76195068 -0.83857726 -0.67327229 -0.71518897\n",
      " -0.61941665 -0.15761758 -0.55728185 -0.65712103 -0.54229607 -0.18583237\n",
      "  0.51288449]\n"
     ]
    }
   ],
   "source": [
    "m,cost_array = fit(X_train_scaled,Y_train,5000,0.01)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cost_array)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = predict(X_train_scaled,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.12206572769952"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(Y_train,y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = np.append(X_val_scaled,np.ones(X_val_scaled.shape[0]).reshape(-1,1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = predict(X_val_scaled,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.3006993006993"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(Y_val,y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
